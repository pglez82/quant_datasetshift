{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quapy as qp\n",
    "\n",
    "#configuration\n",
    "seed = 2032\n",
    "\n",
    "#mean used to generate the covariates in test\n",
    "test_mus=[-1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "test_std = 2\n",
    "\n",
    "train_mu = 1\n",
    "train_std = 2 #mu and std to describe how the train set is generated\n",
    "mu_neg = 0\n",
    "std_neg = 0.5 #mu and std describing negative examples\n",
    "mu_pos = 2 \n",
    "std_pos = 0.5 #mu and std describing positive examples\n",
    "\n",
    "error_function = qp.error.mae\n",
    "\n",
    "ntrain = 500 #number of examples in each training bag\n",
    "ntest = 500 #number of examples in each test bag\n",
    "nreps = 10 #number of repetitions of the whole experiment\n",
    "n_test_samples = 50 #number of test samples with each covariate shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_probabilities(x, mu1, std1, mu2, std2):\n",
    "    probs = np.zeros(len(x))\n",
    "    den1 = 1.0 / (std1 * math.sqrt(2 * math.pi))\n",
    "    den2 = 1.0 / (std2 * math.sqrt(2 * math.pi))\n",
    "    for i in range(len(x)):\n",
    "        pdf1 = den1 * math.exp(-(x[i] - mu1) ** 2 / (2 * std1 ** 2))\n",
    "        pdf2 = den2 * math.exp(-(x[i] - mu2) ** 2 / (2 * std2 ** 2))\n",
    "        probs[i] = 1 - ( (pdf1 / pdf2) / (1 + pdf1 / pdf2) )\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "def generate_dataset_covariate_shift(rng, n_examples, x_mu, x_std, mu1, std1, mu2, std2):\n",
    "    \"\"\"Returns a dataset generated with a normal distribution x_mu x_std\n",
    "    labels are computed following two distributions one for negatives N(mu1,std1) and\n",
    "    N(mu2,std2) for positives\n",
    "    \"\"\"\n",
    "    x = x_std * rng.randn(n_examples, 1) + x_mu\n",
    "    probs = compute_probabilities(x, mu1, std1, mu2, std2)\n",
    "    coins = rng.rand(n_examples)\n",
    "    y = np.zeros(n_examples, dtype=int)\n",
    "    y[np.where(coins < probs)] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "quant_methods = {\n",
    "    \"CC\":qp.method.aggregative.CC(LogisticRegression(max_iter=1000)),\n",
    "    \"PCC\":qp.method.aggregative.PCC(LogisticRegression(max_iter=1000)),\n",
    "    \"ACC\":qp.method.aggregative.ACC(LogisticRegression(max_iter=1000), val_split=5, n_jobs=-1),\n",
    "    \"PACC\":qp.method.aggregative.PACC(LogisticRegression(max_iter=1000), val_split=5, n_jobs=-1),\n",
    "    \"HDy\":qp.method.aggregative.HDy(LogisticRegression(max_iter=1000)),\n",
    "    \"EMQ\":qp.method.aggregative.EMQ(CalibratedClassifierCV(LogisticRegression(max_iter=1000),n_jobs=-1)),\n",
    "    \"MLPE\":qp.method.non_aggregative.MaximumLikelihoodPrevalenceEstimation()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Test mu= -1.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= -1 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= -0.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 0 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 0.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 1 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 1.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 2 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 2.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 3 Rep# 1 2 3 4 5 6 7 8 9 10 \n",
      "#Test mu= 3.5 Rep# 1 2 3 4 5 6 7 8 9 10 \n"
     ]
    }
   ],
   "source": [
    "from quapy.data.base import LabelledCollection\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "experiment_results={}\n",
    "for method_name in quant_methods.keys():\n",
    "    experiment_results[method_name] = pd.DataFrame(columns=[\"train_rep\",\"test_sample\",\"test_mu,\",\"p_train\",\"p_test\",\"error\"])\n",
    "\n",
    "for i, test_mu in enumerate(test_mus):\n",
    "    print('#Test mu=', test_mu, 'Rep#', end=' ')\n",
    "    for rep in range(nreps):\n",
    "        print(rep+1, end=' ')\n",
    "        x_train, y_train = generate_dataset_covariate_shift(rng, ntrain, train_mu, train_std, mu_pos, std_pos, mu_neg, std_neg)\n",
    "        train = LabelledCollection(x_train,y_train)\n",
    "        for quantifier in quant_methods.values():\n",
    "            quantifier.fit(train)\n",
    "        for n_test_sample in range(n_test_samples):\n",
    "            x_test, y_test = generate_dataset_covariate_shift(rng, ntest, test_mu, test_std, mu_pos, std_pos, mu_neg, std_neg)\n",
    "            test = LabelledCollection(x_test,y_test)\n",
    "            for quant_name, quantifier in quant_methods.items():\n",
    "                preds = quantifier.quantify(test.X)\n",
    "                true = test.prevalence()\n",
    "                error = error_function(true,preds)\n",
    "                experiment_results[quant_name] = experiment_results[quant_name].append([{'test_mu':test_mu,\n",
    "                                                        'p_train':train.prevalence()[1],\n",
    "                                                        'train_rep':rep,\n",
    "                                                        'test_sample':n_test_sample,\n",
    "                                                        'p_test':test.prevalence()[1],\n",
    "                                                        'error':error}],ignore_index=True)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quant_name, quantifier in quant_methods.items():\n",
    "    #add date to file name\n",
    "    date_string = f'{datetime.now():%Y_%m_%d_%H_%M}'\n",
    "    #save pandas dataframe\n",
    "    experiment_results[quant_name].to_csv(\"results/covariate/results_%s_%s.csv\" % (date_string,quant_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aebf59cd4c26cc229022e8f1603fcc12869c5f6ee7fb2cbcb8abbf56aa0602b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
