{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon reviews\n",
    "\n",
    "Loading the dataset a printing some data about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading /media/nas/pgonzalez/quant_datasetshift/datasets/reviews/Electronics.txt: 100%|██████████| 2083988/2083988 [00:02<00:00, 1005359.99it/s]\n",
      "loading /media/nas/pgonzalez/quant_datasetshift/datasets/reviews/Books.txt:  92%|█████████▏| 7969282/8623133 [00:09<00:00, 897788.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format error in Funnily enough, that makes it a better book.  I guess the author has come to realise that nine of his thirteen points were about money.  So he got a very funny (but impossibly lazy, he could not even be bothered to dig beyond his personal experience for new stories/examples) co-author to repackage those ideas and hey, presto, a better-focused book is on the shelves.  Also, a major beef of mine with psychologists is they have to get sex into everywhere, a fact that makes it impossible to recommend their books to my mom or even to read their work on the tube.  With point #6 expunged, this is indeed a book you can recommend to your mom and a book you can read in the tube with little risk of embarrassment.  Modulo the jarringly frequent invocation of a dominatrix throughout the text, that is.  So to all those of you whove never read Dan Ariely before, you can now skip his original opus.  Buy Small Change instead, supplement it with The Honest Truth about Dishonesty and be on the lookout for his upcoming work on social norms vs. market norms.  On the other hand, if youve already read Predictably Irrational, I cant recommend buying this book.  Like myself, youll feel robbed of your valuable reading time.  And of whatever not-so-small change you paid for it, of course.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading /media/nas/pgonzalez/quant_datasetshift/datasets/reviews/Books.txt: 100%|██████████| 8623133/8623133 [00:09<00:00, 877801.71it/s]\n",
      "loading /media/nas/pgonzalez/quant_datasetshift/datasets/reviews/CDs_and_Vinyl.txt: 100%|██████████| 1140936/1140936 [00:01<00:00, 974228.82it/s]\n",
      "loading /media/nas/pgonzalez/quant_datasetshift/datasets/reviews/Home_and_Kitchen.txt: 100%|██████████| 1879697/1879697 [00:02<00:00, 865411.58it/s] \n"
     ]
    }
   ],
   "source": [
    "from quapy.data.reader import from_text\n",
    "from quapy.data.base import LabelledCollection\n",
    "import os\n",
    "\n",
    "base_path = \"/media/nas/pgonzalez/quant_datasetshift/datasets/reviews\"\n",
    "subsample_size = 10000 #Subsample for the sake of speed\n",
    "\n",
    "domains_full = {\n",
    "    \"electronics\": LabelledCollection.load(os.path.join(base_path, \"Electronics.txt\"), from_text),\n",
    "    \"books\": LabelledCollection.load(os.path.join(base_path, \"Books.txt\"), from_text),\n",
    "    \"cds\": LabelledCollection.load(os.path.join(base_path,  \"CDs_and_Vinyl.txt\"), from_text),\n",
    "    \"home\": LabelledCollection.load(os.path.join(base_path, \"Home_and_Kitchen.txt\"), from_text)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 3 starts reviews and binarize\n",
    "for domain, lc in domains_full.items():\n",
    "    instances, labels = lc.Xy\n",
    "    # Remove 3 stars reviews\n",
    "    labels, instances = labels[labels!=3], instances[labels!=3]\n",
    "    # Binarize\n",
    "    labels[labels<3] = 0\n",
    "    labels[labels>3] = 1\n",
    "    domains_full[domain] = LabelledCollection(instances,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing some data about each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electronics:\n",
      "#instances=1889965, type=<class 'str'>, #features=?, #classes=[0 1], prevs=[0.300, 0.700]\n",
      "{'instances': 1889965, 'type': <class 'str'>, 'features': '?', 'classes': array([0, 1]), 'prevs': '[0.300, 0.700]'}\n",
      "books:\n",
      "#instances=7813813, type=<class 'str'>, #features=?, #classes=[0 1], prevs=[0.181, 0.819]\n",
      "{'instances': 7813813, 'type': <class 'str'>, 'features': '?', 'classes': array([0, 1]), 'prevs': '[0.181, 0.819]'}\n",
      "cds:\n",
      "#instances=1052258, type=<class 'str'>, #features=?, #classes=[0 1], prevs=[0.113, 0.887]\n",
      "{'instances': 1052258, 'type': <class 'str'>, 'features': '?', 'classes': array([0, 1]), 'prevs': '[0.113, 0.887]'}\n",
      "home:\n",
      "#instances=1695843, type=<class 'str'>, #features=?, #classes=[0 1], prevs=[0.292, 0.708]\n",
      "{'instances': 1695843, 'type': <class 'str'>, 'features': '?', 'classes': array([0, 1]), 'prevs': '[0.292, 0.708]'}\n"
     ]
    }
   ],
   "source": [
    "for name, domain in domains_full.items():\n",
    "    print(\"%s:\" % name)\n",
    "    print(domain.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing how different is each domain\n",
    "He idea is to train a simple classifier for each domain and apply that to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[electronics] Getting a subsample of the domain\n",
      "[electronics] Splitting in train and test\n",
      "Dataset= #tr-instances=6000, #te-instances=4000, type=<class 'str'>, #features=?, #classes=[0 1], tr-prevs=[0.500, 0.500], te-prevs=[0.500, 0.500]\n",
      "[books] Getting a subsample of the domain\n",
      "[books] Splitting in train and test\n",
      "Dataset= #tr-instances=6000, #te-instances=4000, type=<class 'str'>, #features=?, #classes=[0 1], tr-prevs=[0.500, 0.500], te-prevs=[0.500, 0.500]\n",
      "[cds] Getting a subsample of the domain\n",
      "[cds] Splitting in train and test\n",
      "Dataset= #tr-instances=6000, #te-instances=4000, type=<class 'str'>, #features=?, #classes=[0 1], tr-prevs=[0.500, 0.500], te-prevs=[0.500, 0.500]\n",
      "[home] Getting a subsample of the domain\n",
      "[home] Splitting in train and test\n",
      "Dataset= #tr-instances=6000, #te-instances=4000, type=<class 'str'>, #features=?, #classes=[0 1], tr-prevs=[0.500, 0.500], te-prevs=[0.500, 0.500]\n"
     ]
    }
   ],
   "source": [
    "from quapy.data.base import Dataset\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "#Create the datasets\n",
    "for name, domain_full in domains_full.items():\n",
    "    print(\"[%s] Getting a subsample of the domain\" % name)\n",
    "    domain = domain_full.sampling(subsample_size,0.5,0.5)\n",
    "    print(\"[%s] Splitting in train and test\" % name)\n",
    "    train, test = domain.split_stratified(train_prop=0.6)\n",
    "    datasets[name] = Dataset(train,test)\n",
    "    datasets[name].stats(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[electronics] Training the model\n",
      "(6000, 9438)\n",
      "[books] Training the model\n",
      "(6000, 15423)\n",
      "[cds] Training the model\n",
      "(6000, 14109)\n",
      "[home] Training the model\n",
      "(6000, 7909)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "models = {}\n",
    "vectorizers = {}\n",
    "\n",
    "#Train the models for each domain\n",
    "for name, dataset in datasets.items():\n",
    "    print(\"[%s] Training the model\" % name)\n",
    "    vectorizers[name] = TfidfVectorizer(min_df=3, sublinear_tf=True)\n",
    "    training_documents = vectorizers[name].fit_transform(dataset.training.instances)\n",
    "    dataset.training = LabelledCollection(training_documents, dataset.training.labels, dataset.classes_)\n",
    "    X_train, y_train = dataset.training.Xy\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows are the dataset in which the model was trained, columns are the dataset in which the model each model is tested\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>electronics</th>\n",
       "      <th>books</th>\n",
       "      <th>cds</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>electronics</th>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.7680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cds</th>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.7385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.8632</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.8908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df = pd.DataFrame(columns=datasets.keys(), index=models.keys())  \n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for ds_name, dataset in datasets.items():\n",
    "        test_documents = vectorizers[model_name].transform(dataset.test.instances)\n",
    "        X_test, y_test = test_documents, dataset.test.labels\n",
    "        y_pred = model.predict(X_test)\n",
    "        df.loc[model_name, ds_name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Rows are the dataset in which the model was trained, columns are the dataset in which the model each model is tested\")\n",
    "display(HTML(df.to_html(float_format='{:20,.4f}'.format)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table to put in the paper with info about the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "export_dir = '/home/pgonzalez/Dropbox/quant_datasetshift/'\n",
    "\n",
    "info = pd.DataFrame(index=('books','electronics'),columns=('instances','p'))\n",
    "info.loc['books','instances'] = len(domains_full['books'].instances)\n",
    "info.loc['electronics','instances'] = len(domains_full['electronics'].instances)\n",
    "info.loc['books','p'] = domains_full['books'].prevalence()[1]\n",
    "info.loc['electronics','p'] = domains_full['electronics'].prevalence()[1]\n",
    "\n",
    "\n",
    "with open(os.path.join(export_dir,'tables/datasets_info.tex'), 'w') as f:\n",
    "    f.write(info.style.format({(\"p\"): '{:.2f}'}).to_latex(hrules=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv33': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "decae0160c8d3cde08be496d15a3cac098095f2ddec751438a22a3a69caccbf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
